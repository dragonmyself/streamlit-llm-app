import streamlit as st
import os
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

# --- ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ ---
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# --- LLMå›ç­”é–¢æ•° ---
def get_llm_response(user_input: str, expert_type: str) -> str:
    """å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’å—ã‘å–ã‚Šã€LLMã‹ã‚‰ã®å›ç­”ã‚’è¿”ã™"""
    
    if expert_type == "åŒ»å¸«":
        system_prompt = "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªå†…ç§‘åŒ»ã§ã™ã€‚å°‚é–€ç”¨èªã‚’ä½¿ã‚ãšã«ã€æ‚£è€…ã«åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
    elif expert_type == "çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ":
        system_prompt = "ã‚ãªãŸã¯å¤–è³‡ç³»ã®çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ­ã‚¸ã‚«ãƒ«ã«èª²é¡Œè§£æ±ºã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¦ãã ã•ã„ã€‚"
    else:
        system_prompt = "ã‚ãªãŸã¯æœ‰èƒ½ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆAIã§ã™ã€‚åˆ†ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚"

    llm = ChatOpenAI(
        model_name="gpt-4o-mini",
        temperature=0.5,
        openai_api_key=OPENAI_API_KEY
    )

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_input),
    ]
    response = llm(messages)
    return response.content

# --- Streamlit UI ---
st.title("ğŸ§‘â€ğŸ’» LangChain Ã— Streamlit ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒª")
st.write("ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€å…¥åŠ›ã—ãŸè³ªå•ã«å¯¾ã—ã¦AIãŒå°‚é–€å®¶ã®è¦–ç‚¹ã§å›ç­”ã—ã¾ã™ã€‚")
st.write("ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‹ã‚‰å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸ã³ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦é€ä¿¡ã—ã¦ãã ã•ã„ã€‚")

# ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ï¼ˆå°‚é–€å®¶ã®ç¨®é¡ï¼‰
expert_type = st.radio(
    "å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠã—ã¦ãã ã•ã„",
    ("åŒ»å¸«", "çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ")
)

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
user_input = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("é€ä¿¡"):
    if user_input:
        response = get_llm_response(user_input, expert_type)
        st.subheader("AIã‹ã‚‰ã®å›ç­”")
        st.write(response)
    else:
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
